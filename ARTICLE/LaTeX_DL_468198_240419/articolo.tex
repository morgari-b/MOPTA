%%%%%%%%%%%%%%%%%%%%%%% file template.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is a general template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% Copy it to a new file with a new name and use it as the basis
% for your article. Delete % signs as needed.
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
\begin{filecontents*}{example.eps}
%!PS-Adobe-3.0 EPSF-3.0
%%BoundingBox: 19 19 221 221
%%CreationDate: Mon Sep 29 1997
%%Creator: programmed by hand (JK)
%%EndComments
gsave
newpath
  20 20 moveto
  20 220 lineto
  220 220 lineto
  220 20 lineto
closepath
2 setlinewidth
gsave
  .4 setgray fill
grestore
stroke
grestore
\end{filecontents*}
%
\RequirePackage{fix-cm}
%
%\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
\documentclass[smallextended,envcountsame]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{graphicx}
%
\usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{eurosym}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{setspace}
\usepackage{color}
\usepackage{fancyhdr}
\usepackage{ragged2e}
\usepackage{appendix}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{xfrac}
\usepackage{pgfplots}
\usepackage{url}
\usepackage{emptypage}
\usepackage{wrapfig}
\usepackage{dsfont}
\usepackage{soul}

\usepackage{csquotes}
\usepackage{hyperref}

%
% please place your own definitions here and don't use \def but
% \newcommand{}{}


\usepackage{xcolor}
\usepackage{todonotes}
\newcommand{\gr}[2][]{\todo[color=violet!40!,#1]{\textsf{GR:} #2}}
\newcommand{\bm}[2][]{\todo[color=blue!20,#1]{\textsf{BM:} #2}}

%\newtheorem{example}{Example}
\newtheorem{assumption}{Assumption}
%\newtheorem{definition}{Definition}
%\newtheorem{theorem}{Theorem}
%\newtheorem{corollary}{Corollary}[theorem]
%\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{observation}[theorem]{Observation}
%\newtheorem{problem}{Problem}

\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\dw}{d_w}
\DeclareMathOperator{\C}{C_{tc}}
\DeclareMathOperator{\T}{T}
\DeclareMathOperator{\MP}{MP}
\DeclareMathOperator{\KP}{KP}
\DeclareMathOperator{\K}{K}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\SSpan}{Span}
%\DeclareMathOperator{\lim}{lim}
\DeclareMathOperator{\epi}{epi}
\DeclareMathOperator{\supp}{supp}


%\numberwithin{definition}{section}
\numberwithin{theorem}{section}
%\numberwithin{problem}{section}
\newcommand{\nc}{\newcommand}
\nc{\boB}{{\mathbf{B}}}
\nc{\boL}{{\mathbf{L}}}
\nc{\boY}{{\mathbf{Y}}}
\nc{\boI}{{\mathbf{I}}}
\nc{\boV}{{\mathbf{V}}}
\nc{\boS}{{\mathbf{S}}}
\nc{\tV}{{\Tilde{{V}}}}
\nc{\tI}{{\Tilde{{I}}}}
\nc{\tY}{{\Tilde{{Y}}}}
\nc{\tS}{{\Tilde{{S}}}}
\nc{\fr}{{\rightarrow}}
\nc{\co}{{\nabla}}
\nc{\E}{\mathbb{E}}
\nc{\CG}{C_{\Sigma}^{\text{Gauss}}}
\nc{\var}{Var}
\nc{\rows}{S}
\nc{\cols}{R}
\nc{\rowP}{\sigma}
\nc{\colP}{\delta}

\nc{\sS}{ \mathscr{S}}
\nc{\sC}{ \mathscr{C}}
\nc{\cH}{{\mathcal H}}
\nc{\cR}{{\mathcal R}}
\nc{\cA}{{\mathcal A}}
\nc{\cG}{{\mathcal G}}
\nc{\cC}{{\mathcal C}}
\nc{\cD}{{\mathcal D}}
\nc{\cO}{{\mathcal O}}
\nc{\cI}{{\mathcal I}}
\nc{\cB}{{\mathcal B}}
\nc{\cY}{{\mathcal Y}}
\nc{\cK}{{\mathcal K}} 
\nc{\cX}{{\mathcal X}}
\nc{\cS}{{\mathcal S}}
\nc{\cE}{{\mathcal E}}
\nc{\cF}{{\mathcal F}}
\nc{\cZ}{{\mathcal Z}}
\nc{\cQ}{{\mathcal Q}}
\nc{\cP}{{\mathcal P}}
\nc{\cL}{{\mathcal L}}
\nc{\cM}{{\mathcal M}}
\nc{\cN}{{\mathcal N}}
\nc{\cT}{{\mathcal T}}
\nc{\cW}{{\mathcal W}}
\nc{\cU}{{\mathcal U}}
\nc{\cJ}{{\mathcal J}}
\nc{\cV}{{\mathcal V}}
\nc{\bH}{{\mathbb H}}
\nc{\bA}{{\mathbb A}}
\nc{\bG}{{\mathbb G}}
\nc{\bC}{{\mathbb C}}
\nc{\bO}{{\mathbb O}}
\nc{\bI}{{\mathbb I}}
\nc{\bB}{{\mathbb B}}
\nc{\bY}{{\mathbb Y}}
\nc{\bK}{{\mathbb K}} 
\nc{\bX}{{\mathbb X}}
\nc{\bS}{{\mathbb S}}
\nc{\bE}{{\mathbb E}}
\nc{\bF}{{\mathbb F}}
\nc{\bZ}{{\mathbb Z}}
\nc{\bQ}{{\mathbb Q}}
\nc{\bN}{{\mathbb N}}
\nc{\bP}{{\mathbb P}}
\nc{\bL}{{\mathbb L}}
\nc{\bM}{{\mathbb M}}
\nc{\bT}{{\mathbb T}}
\nc{\bW}{{\mathbb W}}
\nc{\bU}{{\mathbb U}}
\nc{\bD}{{\mathbb D}}
\nc{\bJ}{{\mathbb J}}
\nc{\bV}{{\mathbb V}}
\nc{\bR}{{\mathbb R}}


\newcommand{\virgolette}[1]{``#1''} %\virgolette{questo č fra virgolette}%
%\usepackage{frontespizio}
\newcommand{\abs}[1]{\lvert#1\rvert}



%
% Insert the name of "your journal" with
\journalname{Optimization and Engineering}
%
\begin{document}

\title{Modeling of a fully reneweable energy grid with hydrogen storage.
%\thanks{Grants or other notes
%about the article that should go on the front page should be
%placed here. General acknowledgments should be placed at the end of the article.}
}
\subtitle{A stochastic 
approach considering time interdependence of wind and solar power.}

%\titlerunning{Short form of title}        % if too long for running head

\author{Bianca Urso         \and
        Gabor Riccardi %etc.
}

%\authorrunning{Short form of author list} % if too long for running head

\institute{B. Urso \at
              IUSS School of Advances Studies, Palazzo del Broletto, Piazza della Vittoria, 15 – 27100 Pavia PV, Italy\\
              Tel: +39 0382 375811\\
              Fax: +39 0382 375899\\
              \email{bianca.urso@iusspavia.it}           %  \\
%             \emph{Present address:} of F. Author  %  if needed
           \and
           G. Riccardi \at
           Dipartimento di Matematica ”F. Casorati”
           Via Adolfo Ferrata, 5 – 27100 Pavia
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle

\begin{abstract}
  In recent years, the integration of renewable energy sources into electrical grids has become a
   critical area of research due to the increasing need for sustainable
  and resilient energy systems.  To adress the
   variability of wind and solar power output over time, electricity grids expansion plans need to account for multiple scenarios over large time horizons.
   This significanlty increases the size of the resulting Linear Problem (LP), making them computationally challenging for large scale grids.
  To tackle this, we propose an approach that aggregates time steps to reduce the problem size, 
  followed by an iterative refinement of the aggregation. We provide sufficient conditions under which
   the aggregated problem is equivalent to the original, unaggregated one, and refine the time intervals
    that do not meet these conditions. \textcolor{violet}{write better:Additionally, we introduce a validation function to assess the accuracy
     of the aggregated solutions.}
Our method is tested on a fully renewable energy grid with hydrogen storage.
 We generate scenarios for wind and photovoltaic (PV) power output using scenario generation techniques that capture temporal dependencies. 
 These dependencies are modeled with marginal distributions coupled with a Gaussian copula, ensuring that the generated scenarios reflect realistic 
 temporal correlations observed in historical data.
%Insert your abstract here. Include keywords, PACS and mathematical
%subject classification numbers as needed.
\keywords{First keyword \and Second keyword \and More}
% \PACS{PACS code1 \and PACS code2 \and more}
\subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

\newpage
\section{INTRODUCTION}

\textbf{Context; literature overview. Small introduction on LP/MIP. Definition of stochastic optimization,
definition of CEP, ED problems.}\\

The threat of climate change is pushing policy-makers to pursue greater integration of renewable energy sources into electrical grids, while at the same time ensuring reliability and resilience of the grids. The model presented in this report explores the possibility of an electrical grid powered entirely through wind and photovoltaic (PV) systems, and supported by hydrogen storage.
It is of interest to estimate the power generation capacity for both wind and solar, as well as the hydrogen storage and conversion capacities, that would be necessary in order to power a reliable grid supplying residential electricity load and industrial base load of both electricity and hydrogen for a given area, while minimizing the cost of implementing such infrastructure.
The main difficulties arising when designing such a system lie in the great variability of the generation of electricity through wind and solar, since these resources are highly dependent on weather conditions, making it impossible to plan long-term by optimizing on forecasts, and requiring a statistical approach to ensure a robust model.

A first step for estimating the optimal capacities is thus to have realistic scenarios on which to evaluate our model.
To generate the scenarios for wind and solar power generation we sampled from a joint probability density function (PDF) that was fit on historical data. The construction of the PDF for wind and solar is explained in detail in subsections \ref{subsection: weib estim} and \ref{subsection: beta estim} respectively. 
  In this simple model, while fitting on historical data we did not account for possible changes in future climate.\\
On the other hand, electricity load is taken from the \textcolor{yellow}{\href{https://www.entsoe.eu/data/power-stats/}{ENTSO-E Statistical Reports}}. We normalised the 2023 data by country to indicate the trend of load throughout the year, dividing by mean hourly load: \textcolor{green}{this is then to be multiplied by the mean load of the area the policy maker is interested in serving with the modeled grid.}

The scenario generation step is followed by an optimization process. The model, as described in section \ref{section: model}, takes in input the generation and load scenarios of the selected countries along with various parameters indicating costs and efficiency of the current state of technology and possible upper bounds for the decision variables, and returns the optimized capacity that is necessary to meet demand throughout a one year span, with minimal cost. The optimization problem is solved using the Gurobi solver.
When optimizing over multiple scenarios jointly, the solver returns the minimal amount of infrastructure and capacities that is needed to have feasibility (that is, demand met at all time - no blackouts) over all scenarios in input, with minimal average cost over the scenarios.

When considering a network with more than a single node, computational costs increase rapidly. Thus a small analysis is carried out to determine acceptable time steps on which time dependent data can be aggregated (the gathered data is usually on hourly steps) while maintaining the quality of the solution. 
Results are then evaluated for a single node network and for more complex networks based in the European Union, for which the necessary data was publicly available. Appropriate validation functions are discussed to check feasibility over new scenarios, along with cost functions that give more realistic cost estimates compared to the optimal value given by the solver.

\section{MODEL}

\subsection{SCENARIO GENERATION}
\textbf{To estimate the optimal capacities through a stochastic approach, realistic weather scenarios (and thus
generation scenarios) are needed. To generate the scenarios for wind and solar power generation, samples
are extracted from a joint probability density function (PDF) that was fit on historical data. The
construction of the joint PDF for wind and solar is done through a Gaussian Copula approach.
A first section will explain the theory behind this approach, and a second section will show the
application in the case of weather conditions in European countries. Weibull distributions are used as
marginals to model wind, and beta distributions for solar power.}\\


Wind and solar power are inherently intermittent and uncertain, posing a challenge to their successful integration into the energy system. Hydrogen storage and other forms of energy storage offer potential solutions to mitigate these issues. However, the amount of long-term storage required in a fully renewable grid is heavily influenced by the stochastic behavior of wind and solar power. Moreover, historical data typically covers only a limited number of climate years, which restricts the ability to test the grid over long time horizons encompassing various climatic conditions. To address this limitation, we adopted a scenario generation (SG) method based on historical data of each of the European countries considered, allowing us to create realistic and diverse scenarios that better capture the variability and uncertainty of renewable energy sources over extended periods. 

To model the probability distribution corresponding to the power output of wind turbines for each hour of the year, we utilized a Weibull distribution, justified by its proven effectiveness in capturing the variability and skewness of wind power distributions [\cite{weibullwind}]. For solar power, a Beta distribution was employed in [\cite{betaPV}]. \textcolor{yellow}{controllare che siamo coerenti con tutte le cose che citiamo} To account for interdependence between temporally near time steps, we coupled these distributions using a Gaussian Copula approach, which captures the dependencies between hourly power outputs effectively. This approach accurately mimics common weather phenomena. \\

\subsubsection{Stochastic Processes description}
The stochastic processes of power observations will be denoted as \(Y_t\). Where \(t \in T\), is the set indexing all the random variables which want to be considered jointly.
We assume that the random variable \(Y_t\) has either a Weibull distribution, in the case of Wind Power, or a Beta distribution in the case of Solar Power. 

\subsubsection{Parametric Estimation of Wind Power distribution}
\label{subsection: weib estim}
The parameters defining the Weibull Distribution are estimated using the Maximum Likelyhood Estimation. The Weibull density function is given by:
\[
f(x; \theta, \gamma) = \left(\frac{\gamma}{\theta}\right)x^{\gamma-1}\exp\left(-\left(\frac{x}{\theta}\right)^\gamma\right)
\]

where \(\theta, \gamma > 0\) are the scale and shape parameters, respectively. Given observations \(X_1, \ldots, X_n\), the log-likelihood function is:

\[
\log L(\theta, \gamma) = \sum_{i=1}^n \log f(X_i \mid \theta, \gamma)
\]

The optimum solution is found by searching for the parameters for which the gradient is zero :

\begin{equation}
\frac{\partial \log L}{\partial \theta} = -\frac{n \gamma}{\theta} + \frac{\gamma}{\theta^2} \sum_{i=1}^{n} x_i^\gamma = 0
\end{equation}

Eliminating $\theta$, we get:

\begin{equation}
\left[ \frac{\sum_{i=1}^{n} x_i^\gamma \log x_i}{\sum_{i=1}^{n} x_i^\gamma} - \frac{1}{\gamma} \right] = \frac{1}{n} \sum_{i=1}^{n} \log x_i
\end{equation}

This can be solved to get the MLE estimate $\hat{\gamma}$. This can be accomplished with the aid of standard iterative procedures such as the Newton-Raphson method or other numerical procedures. This is done with the aid of the package \emph{scipy}. Once $\hat{\gamma}$ is found, $\hat{\theta}$ can be determined in terms of $\hat{\gamma}$ as:

\begin{equation}
\hat{\theta} = \left( \frac{1}{n} \sum_{i=1}^{n} x_i^{\hat{\gamma}} \right)^{\frac{1}{\hat{\gamma}}}
\end{equation}

\subsubsection{Parametric Estimation of Solar Power distribution}
\label{subsection: beta estim}
To estimate the \(\alpha\) and \(\beta\) parameters defining the Beta distribution \(Y\), we use the \emph{Method of Moments}.
The mean of the random variable \(Y\) can be expressed as \(\E\left[ Y\right] = \frac{\alpha}{\alpha + \beta} \) and the variance as \(\var [Y]= \frac{\alpha + \beta}{(\alpha + \beta)(\alpha + \beta + 1)}\). In particular by explicating \(\beta\) in the first equation and substituting it in the second equation we obtain that:
\begin{equation}
\begin{cases}
\alpha = \mathbb{E}[X] \left( \frac{\mathbb{E}[X](1 - \mathbb{E}[X])}{\mathrm{Var}[X]} - 1 \right) \\
\beta = (1 - \mathbb{E}[X]) \left( \frac{\mathbb{E}[X](1 - \mathbb{E}[X])}{\mathrm{Var}[X]} - 1 \right)
\end{cases}
\end{equation}
By substituting the mean and the variance with their empirical approximation we obtain the method of moments estimator for \(\alpha\) and \(\beta\).

\subsubsection{Parametric Copula Estimation}
The cumulative density function of both the Weibull and Beta distributions are continuous and invertible. Therefore, the random variables \( U_t \coloneqq F_{Y_t}(Y_t) \) have a uniform distribution over \([0,1]\). The copula of the random variables \(\{Y_t\}_{t \in T}\) is defined as the function \(C: [0,1]^T \to [0,1]\) such that 
\begin{equation}
C(F_{Y_1}(y_1), \ldots, F_{Y_T}(y_{|T|})) = P(Y_1 \leq y_1, \ldots, Y_{|T|} \leq y_{|T|}).
\end{equation}
This function always exists because of Sklar's Theorem. The Gaussian Copula represents well the coupled behavior in renewable stochastic systems [\cite{GaussCopula}] and is the one used in this project. For a given correlation matrix \(\Sigma\), the Gaussian Copula with parameter matrix \(\Sigma\) is defined as \(\CG(u_1,\ldots,u_{T}) \coloneqq \Phi_{\Sigma}(\Phi^{-1}(u_1),\ldots, \Phi^{-1}(u_T))\). Where \(\Phi,\; \Phi_{\Sigma}\) are the cdf Gaussian variables having distribution \(\mathcal{N}(0,1)\) and \( \mathcal{N}(0,\Sigma)\) respectively. In particular if \(\CG\) is the copula associated the random variables \(\{Y_t\}_{t \in T}\) then we have that the random variables \(Z_t = \Phi^{-1}(F_{Y_t}(Y_t) = \Phi^{-1}(U_t)\) have joint distribution equal to \(\mathcal{N}(0, \Sigma)\). This follows from: \\
\begin{align*}
P(Z_1 \leq z_1, \ldots, Z_T \leq z_t) &= P(\Phi^{-1}(U_1) \leq z_1, \ldots, \Phi^{-1}(U_T) \leq z_T) \\
&= P(U_1 \leq \Phi(z_1), \ldots, U_T \leq \Phi(z_T)) \\
&= \CG(\Phi(z_1), \ldots, \Phi(z_t)) \\
&= \Phi_{\Sigma}(z_1, \ldots, z_T)
\end{align*}
In particular, given the realization \(\{y_{t,j}\}_{t \in t, j \in J}\) of the variables \(\{Y_t\}_{t \in T}\), an unbiased estimation of the parameter matrix \(\Sigma\) is the empirical covariance matrix \(\hat \Sigma\) of the samples \(\{\Phi^{-1}(\hat{F}_{Y_t}(y_{t,j})\}_{t\in T, j \in J}\), where \(\hat{F}_{Y_t}\) is the estimated marginal distribution of the variable \(Y_t\) as seen in subsection \ref{subsection: weib estim} and subsection \ref{subsection: beta estim}.\\


Finally, we can generate samples from a Multivariate Gaussian random variable \((Z_{t}, t \in T)\) having distribution \(\mathcal{N}(0, \hat \Sigma)\).  Then the power output scenarios are obtained from these samples by following the previous steps backwards, that is, for each sample, computing \(\hat F_{t}^{-1}(\Phi(Z_{t}))\) for all \(t\in T\). \\

\subsubsection{Generation}
In our project, we used an hourly time step (T=\{1...8760\}) and fit the wind and solar distributions \st{separately (thus limiting the computational costs)}jointly (\textcolor{red}{TO DO}). To fit our model, we used a dataset containing 30 years of data for various European countries, which was collected by [\cite{PVDataSet}]. 
For more complex versions of the model, where we considered multiple nodes at the same time, we fit (\textcolor{red}{TO DO}) a joint distribution considering the involved countries, capturing typical correlations of the \textcolor{red}{Northern Atlantic Oscillation... TO DO (image)} 

We observed that the bottleneck of the Scenario Generation algorithm is the Singular Value Decomposition (SVD) of the covariance matrix \(\hat{\Sigma}\). Consequently, the computation time changes marginally with the number of generated scenarios \(d\). Thus, in the GUI, we stored the pre-computed SVD matrices for the European countries we worked with (individually), giving the option to rapidly generate a desired amount of scenarios for those countries. \textcolor{green}{We also give the option to fit new distributions for other areas by inputting one's own historical data, but we would advise doing so on larger time steps to limit the computational time. }
% To reproduce the results simply start the GUI as explained in README.md, insert the number of scenarios to be generated and click on the \emph{generate scenarios} button. 
% Furthermore, the functions found in \emph{scenario_generation.py} can be used to model your own power production distribution on a saved dataset.

A possible extension could be to also include load scenarios jointly with the generation scenarios through the same approach. This would consider dependence between Energy Demand and weather conditions, but it would necessitate of the historical dataset provided for the corresponding grid, and would also further increase computational costs.
%\textcolor{black}
\subsection{LP OPTIMIZATION}

\textbf{The scenario generation step is followed by an optimization process. The model takes in input the
generation and load scenarios of a given area along with various parameters indicating costs and
efficiency of the current state of technology and possible upper bounds for the decision variables, and
returns the optimized capacity that is necessary to meet demand throughout a one year span, with minimal
cost. The optimization problem is solved using the Gurobi solver. When optimizing over multiple
scenarios jointly, the solver returns the minimal amount of infrastructure and capacities that is needed to
have feasibility (that is, demand met at all time - no blackouts) over all scenarios in input, with minimal
average cost over the scenarios.}\\



\section{Optimization and Time Resolution}\label{section:time-resolution}

The time horizon generated by the scenarios has a time resolution where each time step has a length of one hour. Each value represents the total power (hydrogen) production or demand in the corresponding hour at the node. The smaller the length of each time step, the more accurate the results. However, the number of variables and constraints grows linearly with the number of time steps, making the model intractable (especially in the context of an application) with just a few scenarios.

Moreover, considering every hour in each day of the year is partly redundant, as each day will be similar to neighboring days. Yet, simply considering a sample of days for each season might undermine long-term storage capacity representation. 

Given an initial time horizon \(\cT = \{1, \ldots, T\}\), we can consider partitions of \(\cT\) as a family of disjoint subsets whose union is \(\cT\). We only consider those partitions where every subset is an interval of \(\cT\). We refer to these as time partitions. Given a time partition \(P\), we can consider the corresponding model obtained by considering each interval in \(P\) as a single time step. For every \(I\) in \(P\), we define:
\[
ES_{j,I,n} \coloneqq \sum_{i \in I} ES_{j,i,n}, \quad EW_{j,I,n} \coloneqq \sum_{i \in I} EW_{j,i,n}
\]
and similarly for \(HL_{j,I,n}\) and \(HR_{j,I,n}\). We denote the model obtained by the time partition \(P\) as \(CEP_P\).

It is evident that the optimal value of \(CEP_P\) is a lower bound for the original problem \(CEP_{\cT}\), as given a feasible solution \((ns, nw, nh, mhte, meth, H, HtE, EtH, Pedge, Hedge)\) of the latter, we can obtain a solution of the former by taking \((ns, nw, nh, mhte, meth)\) the same as in \(CEP_{\cT}\) and:
\[
Pedge_{j,I,e} = \sum_{i \in I} Pedge_{j,i,e}, \quad Hedge_{j,I,e} = \sum_{i \in I} Hedge_{j,i,e}
\]
and similarly for \(EtH\) and \(HtE\), and \(H_{j,I,n} = H_{j,i_0,n}\) where \(I = [i_0,\ldots,i_{|I|}] \in P\). In particular, there is a cost-preserving linear map from the feasible space of \(CEP_{\cT}\) to the feasible space of \(CEP_P\), making the latter a relaxation of the former.

This is generally true when considering any time partition \(P'\) finer than \(P\), where for every \(t' \in P'\), there exists \(t \in T\) such that \(t' \subset t\). In particular, we have the following observation:

\begin{observation}
Let \(V_{\cP} \subset \bR^{N_{\cP}}\) and \(V_{P'} \subset \bR^{N_{P'}}\) be the space of feasible solutions of \(CEP_{\cP}\) and \(CEP_{P'}\), respectively. There exists a linear map \(L_{P'P}: \bR^{N_{P'}} \to \bR^{N_{P}}\) such that \(L(V_{P'}) \subset V_{P}\) and \(c_{P}(L(x)) = c_{P'}(x)\), where \(c_{P}\) is the cost function of \(CEP_{P}\) and \(c_{P'}\) is the cost function of \(CEP_{P'}\).
\end{observation}

Thus, by iteratively solving finer time partitions, we converge to the optimal solution of \(\cP\).
\subsection{Variables and Constraints aggregation}
\textcolor{violet}{
TODOS:
\begin{itemize}
  \item When is the cost of the aggregated solutions equal to the cost of the original problem respect to the corresponding unaggregated solutioon? \textcolor{red}{done}
  \item When is the corresponding unaggregated solution optimal for the original problem? \textcolor{red}{done}
  \item How to estend obs so that it holds for ED. 
  \item rimuovere che combinazioni devono essere convesse, fa casino e non cambia niente \textcolor{red}{done}
  \item How to get a scenario for which the aggregated ED solution is feasible 
  \item How to easily compute when an aggregated interval is "far" from such fesible scenario
  \item Unaggregate on those intervals first. \textcolor{red}{done}
  \item Add examples
  \item If the non aggregated variables are mixed integers, everything works the same.
  \item For \(\rho_r\) constraints which behave well under generalisez convex combinations of variables can be excluded. \textcolor{red}{done}
\end{itemize}
}
\gr[inline]{Secondo me ci sta scriverlo in maniera un filo generale perchè:
Così questo metodo non è ristretto a solo (ed esattamente) a questo modello,  magari diventa chiaro che aggiungendo generatori tradizionali tutto funciona comunque e top.
Oppure per problemi totalmente diversi ma con una struttura simile.
Poi così alcune dimostrazioni si "semplificano", ad esempio qui il problema della conservazione dei costi nel caso le variabili sono negative non sorgeva perchè ci si è ristretti a una formulazione con variabili positive (alla quale ci si può poi ricondurre come abbiamo visto).}



Varying time aggregation can be viewed as performing row and column aggregation on the original linear programming (LP) model. Consider the following general linear problem:
\begin{align}
\label{eq:LP}
\min_{x \in \bR^{n}} &c^T x \\ 
\text{s.t.} &\quad Ax = b \\
&x \geq 0
\end{align}

Here, \(A\) is an \(m \times n\) matrix. Now, let \(\rowP = \{\rows_1, \rows_2, \ldots, \rows_{\tilde{n}}\}\) be a partition of \([n]\) (the columns) and \(\colP = \{\cols_1, \cols_2, \ldots, \cols_{\tilde{m}}\}\) a partition of \([m]\) (the rows), corresponding to a partition of the rows and columns of \(A\).

We obtain the corresponding aggregated problem by replacing each set \(\rows\) in \(\rowP\) with a single row, and each set \(R\) in \(\colP\) with a single column. One way to aggregate a set of rows (or columns) is by taking a convex combination of the rows (or columns), known as \emph{weighted aggregation}.

The corresponding aggregated LP problem becomes:
\begin{align}
\label{eq:LPaggr}
\min_{\tilde{x} \in \bR^{\tilde{n}}} &\tilde{c}^T \tilde{x} \\ 
\text{s.t.} &\quad \tilde{A} \tilde{x} = \tilde{b} \\ 
&\tilde{x} \geq 0 
\end{align}
where \(\tilde{A}\) is a \(\tilde{m}\times \tilde{n}\) matrix.

In the problem under consideration, we have various types of constraints: Electricity Balance, Hydrogen Balance, Hydrogen Storage, and bounds on the variables. Given a time partition \(P\), we define \(\rowP\) and \(\colP\) such that each set \(S \in \rowP\) corresponds to all constraints of the same type, scenario, and time index \(t\) that falls within the same time interval in \(T\) as \(P\). Similarly, the variables (such as Power generation, Hydrogen generation, etc.) are partitioned in \(\colP\) based on the same criteria.

Rows and columns are combined via equal-weight aggregation. This aggregation maintains the structure of the original problem, 
meaning that had we formulated the model directly with the aggregated time steps, we would have arrived at the same model.
 We refer to this as a \emph{structure-preserving aggregation}, which is defined as follows:

 \begin{definition}
  Given an LP problem \eqref{eq:LP}, we say that a weighted aggregation with respect to partitions \(\rowP, \colP\) is \emph{structure-preserving} if for each \(R \in \rowP\) and each \(r \in R\), there exists a bijection \(f^r: \supp(\tilde{A}_R)_{>1} \to \supp(A_r)_{>1}\) such that \(\tilde{A}_{R,S} = A_{r,f(S)}\). And the following conditions hold:
  \begin{enumerate}
    \item \(f^{r'}(C') = f^r(C) \implies C=C'\)
    \item \(\{f^r(C)\}_{r\in R \in \rowP_{>1}, C \in \colP_{>1}} = \cup_{C \in \colP_{>1}}C\)
  \end{enumerate}
  \end{definition}

\textcolor{violet}{
Per alcune oss le seguendi condizioni si possono togliere: \(f^{r'}(C') = f^r(C) \implies C=C'\) e \(\{f^r(C)\}_{r\in R \in \rowP_{>1}} = \cup_{C \in \colP_{>1}}C\).
Usiamo entrambe le ipotesi aggiuntive più avanti, la prima ci dice che se mandiamo du variabili \(C,C'\) del problema agregato nella stessa variabile, allora le due variabili iniziali sono la stessa. La seconda che a ogni variabili non agregata corrisponde una variabile aggregata.
}
Where if \(F\) is a family of sets we denote as \(F_{=k}, F_{>k}\) respectively the sets of \(F\) with size equal to \(k\) and greater than \(k\).
In particular \(\supp(\tilde{A}_R)_{>1} \subset \colP\) is the set of indices corresponding to sets \(R \in \colP\) of size greater than 1. And \(\supp(A_r)_{>1}\) is the set of indices such that \(r \in R \in \colP\) with \(R\) of size greater than 1.
This implies that the coefficients of the aggregated variables in the aggregated problem match those in the original problem for the corresponding unaggregated variables, \(f^r\) can be seen as a function mapping the aggregated variables to variables of the same "type" in the unaggregated constraint.
 While obtaining a feasible solution to \eqref{eq:LP} from \eqref{eq:LPaggr} is not always guaranteed, it is possible under certain assumptions.
Here, if \(B\) is a matrix having \(I,J\) as set of indexes for the rows and columns respctively, then, for all \(I' \subset I\) and \(J' \subset J\), we denote with \(B_{I',J'}\) the submatrix of \(B\) havins rows in \(I'\) and columns in \(J'\).
\begin{observation}
\label{ob:aggrconstr}
If \((\rowP, \colP)\) is a structure-preserving aggregation, let \(R \in \rowP\) and \(r \in R\). Let \(\tilde{x}\) be a solution to the aggregated problem \eqref{eq:LPaggr}. If \(\tilde{b}_r - \tilde{A}_{R, \colP_{=1}} \tilde{x}_{\colP_{=1}} \neq 0\), define \(\rho_r \coloneqq \frac{b_r - A_{r, \colP_{=1}} \tilde{x}_{\colP_{=1}}}{\tilde{b}_r
 - \tilde{A}_{R, \colP_{=1}} \tilde{x}_{\colP_{=1}}}\). If \(A_{r, \colP_{=1}} = 0\) and \(b_r = 0\), then \(\rho_r\) can be chosen arbitrarily. 

If \(\rho_r \geq 0\) and \(x \in \bR^n\) satisfies \(x_{\colP_{=1}} = \tilde{x}_{\colP_{=1}}\) and \(x_{f^r(C)} = \rho_r \tilde{x}_C\) for all \(C \in \supp(\tilde{A}_R)\), then \(x\) satisfies the constraint \(A_r x = b_r\) of the original problem.
\end{observation}

\begin{proof}
From the hypothesis and the definition of structure-preserving aggregation, we have:
\begin{align*}
A_r x &= \sum_{i \in \supp(A_r)} A_{r,i} x_i \\
&= \sum_{S \in \supp(\tilde{A}_R)_{>1}} A_{r,f(S)} x_{f(S)} + 
\sum_{j \in \colP_{=1}} A_{r,j} x_j \\
&= \sum_{S \in \supp(\tilde{A}_R)_{>1}} \tilde{A}_{R,S} \rho_r \tilde{x}_S + 
\sum_{j \in \colP_{=1}} A_{r,j} x_j
\end{align*}

By the definition of \(\rho_r\):
\begin{align*}
\rho_r \sum_{S \in \supp(\tilde{A}_R)_{>1}} \tilde{A}_{R,S} \tilde{x}_S 
&= \rho_r (\tilde{A}_R \tilde{x} - \tilde{A}_{R,\colP_{=1}} \tilde{x}_{\colP_{=1}}) \\
&= \rho_r (\tilde{b}_R - \tilde{A}_{R,\colP_{=1}} \tilde{x}_{\colP_{=1}}) \\
&= b_r - A_{r, \colP_{=1}} \tilde{x}_{\colP_{=1}}
\end{align*}

Thus, we obtain:
\[
A_r x = b_r
\]
\qed
\end{proof}

\begin{observation}
  \label{ob:rhoconvex}
  Let \(\tilde{\rho}_r \in \bR\) for all \(r \in R \in \rowP\) be the weights of the row aggregation.
  Let \(\rho_r\) for \(r \in R \in \rowP_{>1}\) be defined as in \ref{ob:aggrconstr}, if \(\tilde{\rho}_r \geq 0\). If \(\rho_r\) is well defined for all \(r \in R\), then we have, for all \(R \in \rowP_{>1}\):
  \begin{equation}
    \tilde{\rho}_R^T \rho_R = 1
  \end{equation}
\end{observation}
\begin{proof}
  \[
  \tilde{\rho}_R^T \rho_R = \sum_{r \in R} \tilde{\rho}_r \rho_r =  \frac{\sum_{r \in R}\tilde{\rho}_r(b_r - A_{r, \colP_{=1}} \tilde{x}_{\colP_{=1}})}{\tilde{b}_r
  - \tilde{A}_{R, \colP_{=1}} \tilde{x}_{\colP_{=1}}} = 1
  \] 
\end{proof}

A structure-preserving aggregation does not inherently guarantee feasibility for all constraints in the original problem. However, Observation \ref{ob:aggrconstr} illustrates how to partially reconstruct a solution \(x\) for a specific constraint \(r\) by appropriately scaling the aggregated variables within the support of \(A_r\). 

\begin{definition}
  For a structure-preserving, row and column aggregation \((\rowP,\colP)\), such that \(f^{r'}(C') = f^r(C) \implies C=C'\) and \\ \(\{f^r(C)\}_{r\in R \in \rowP_{>1}, C \in \colP_{>1}} = \cup_{C \in \colP_{>1}}C\).
  A constraint \(r \in \rowP_{=1}\) is \(\rho\)-agnostic if for all \(C \in \colP_{>1}\) such that \(C \cap \supp(A_{r,c}) \neq \emptyset\), 
  \[A_{r,f^{r'}(C)} = \rho_{r'}\tilde{A}_{r,C} \text{ for all } r' \in R^{(C)} \]
   with \(R^{(C)} \in \rowP_{>1}\) such that \(C \in \supp(A_{R^(C)})\).
\end{definition}
\begin{observation}
 Let \(x\) be as in Obs \ref{ob:rhoconvex}. If \(r \in \rowP_{=1}\) is a row-agnostic constraint, then \(A_rx=b_r\).
\end{observation}

\begin{proof}
Since \(\tilde{\rho}_R^T \rho_R = 1\), we have:
  \[
  A_rx = \sum_{C \in \colP_{=1}}A_{r,C}x_{r,C} +  \sum_{C \in \supp(A_{r})_{>1}} \sum_{r' \in R^{(C)}} A_{r,f^{r'}(C)}x_{f^{r'}(C)} = \sum_{C \in \colP_{=1}}\tilde{A}_{r,C}\tilde{x}_{r,C} +  \sum_{C \in \supp(A_{r})_{>1}} \sum_{r' \in R^{(C)}}\tilde{\rho}_{r'} \rho_{r'}\tilde{x}_{R,C} = \tilde{b}_r = b_r
   \]
\end{proof}

We can now define the hypergraph associated to the aggregation \((\rowP, \colP)\).
\begin{definition}
  The \emph{hypergraph associated to the aggregation \((\rowP, \colP)\)} is the hypergraph \(\cN, \cE\) having as nodes the aggregated variables \(\cN \coloneqq \colP_{>1}\) and as edges the subsest of \(\cN\) that appear together in not row-agnostic constraints.
\end{definition}

When two edges (constraints) in the hypergraph, \(r\) and \(r'\), share aggregated variables, the scaling factors \(\rho_r\) and \(\rho_{r'}\) must be equal to maintain consistency. 
Then if \(\rho_r\) can be defined consistently, by applying observation \ref{ob:aggrconstr}, to all \(r \in R \in \rowP_{>1}\) we can construct a feasible solution for the unaggregated problem \eqref{eq:LPunaggr}. Thus we have: 
\begin{proposition}
\label{prop:xaggfeasible}
If \((\rowP, \colP)\) is a structure-preserving aggregation. Let \(\tilde{x}\) be a solution 
to the aggregated problem \eqref{eq:LPaggr}. If for all \(r \in R \in \rowP_{>1}\) such that  \(\tilde{b}_r - \tilde{A}_{R, \colP_{=1}} \tilde{x}_{\colP_{=1}} = 0\) we have \(A_{r,\colP_{=1}} = 0\) and \(b_r=0\).
Define \(\rho_r \coloneqq \frac{b_r - A_{r, \colP_{=1}} \tilde{x}_{\colP_{=1}}}{\tilde{b}_R - \tilde{A}_{R, \colP_{=1}} \tilde{x}_{\colP_{=1}}}\) for all \(r \in R \in \rowP_{>1}\) such that   \(\tilde{b}_r - \tilde{A}_{R, \colP_{=1}} \tilde{x}_{\colP_{=1}} \neq 0\). If \(rho_r \geq 0\) and is constant over the connected components of the hypergraph associated to \((\rowP, \colP)\). 
Then \(x_{\colP_{=1}} \coloneqq \tilde{x}_{\colP_{=1}}\) and \(x_{f^r(C)} \coloneqq \rho_r \tilde{x}_C\) for all \(C \in \supp(\tilde{A}_R)\) and \(C \in \colP_{>1}\) is well defined and is feasible solution for the unaggregated problem \eqref{eq:LP}.
\end{proposition}


\begin{observation}
  \label{ob:costpreserving}
  Let \(x\), \(\tilde{x}\) be as defined as in proposition \ref{prop:xaggfeasible}. If \(\tilde{\rho}_r\tilde{c}_C = c_{f(r,C)}\) for some \(r \in R \in \rowP_{>1}\). Then the cost of \(\tilde{x}\) for the aggregated problem 
  is equal to the cost of \(x\) in the unaggregated problem. 
\end{observation}
\begin{proof}
  Let \(\tilde{x}\) be a solution to the aggregated problem \eqref{eq:LPaggr}. Using observation \ref{ob:rhoconvex}, for all \(C \in \colP_{>1}\) the cost corresponding to the variable \(\tilde{x}_C\) is 
  \[
  \tilde{c}_C\tilde{x}_C = \tilde{c}_C\sum_{r \in R}\tilde{\rho}_r\rho_r\tilde{x}_C = \sum_{r \in R}\tilde{c}_C\tilde{\rho}_r\rho_r\tilde{x}_C  = \sum_{r \in R}c_{f(r,C)}x_{f(r,C)}
  \]
  Which correspond to the cost of the variables \(\{x_{f(r,C)}\}_{r \in R}\). Thus
  \[
  \tilde{c}\tilde{x} = \sum_{C \in \colP_{=1}}\tilde{c}_C\tilde{x}_C + \sum_{C \in \colP_{>1}}\tilde{c}_C\tilde{x}_C = \sum_{C \in \colP_{=1}}c_Cx_C + \sum_{C \in \colP_{>1}}\sum_{r \in R}c_{f(r,C)}x_{f(r,C)} =  \sum_{C \in \colP_{=1}}c_Cx_C + \sum_{j \in \cup_{C \in \colP_{>1}}C}c_{i}x_{i} =  cx
  \]

\end{proof}


While row aggregation of a linear problem is a relaxation of the original problem, the same does not apply to column aggregation. However, the column aggregation used for the  Capacity Expansion Problem in this work is still a relaxation. In general a column aggregation of a linear problem is a relaxation of the original problem whenever it is a \emph{constant-coefficients column aggregation}, that is:
\begin{definition}
  A column aggregation  of a linear problem with weights \(\tilde{\rho}_c,\; c \in C \in \colP \) is a \emph{constant-coefficients column aggregation}  if for all \(c \in C \in \colP\) for all rows \(r \in [m]\), we have \(\tilde{\rho}_cA_{r,c} = \frac{1}{|C|}\) or  \(\tilde{\rho}_cA_{r,c} = 0\).  
\end{definition}

That is if for every set \( C \in \rowP \) of variables that are aggregated together, each variable in \( C \) has the same coefficients in every row of the aggregated problem defined by \( \rowP \) and the coefficient is equal to the aggregation weight of the corresponding variable, except for those rows where all the coefficients of the variables are zero.
We then substitute the columns corresponding to \( C \) with a vector containing one in every row in which the coefficients in \(C\) are non zero, otherwise we substitute with zero.

\begin{proposition}
If \((\rowP,\colP)\) is a structure-preserving, constant-coefficients column aggregation,
if the hypothesis of proposition \ref{prop:xaggfeasible} holds then the aggregated problem \eqref{eq:LPaggr} is exact and \(x\) is an optimal solution.
\end{proposition}

\begin{proof}
  Since for observation \ref{ob:costpreserving}, the cost of the aggregated problem is equal to the cost of \(x\) in the unaggregated problem, we only need to show that the aggregated problem is a relaxation of the unaggregated problem.
  Let \(x\) be a solution to the unaggregated problem \eqref{eq:LP}. For all \(C \in \colP_{=1}\) let \(\tilde{x}_C \coloneqq x_C\).
  Since  \(\{f^r(C)\}_{r \in \cup_{R\in \rowP_{>1}}, C \in \colP} = \cup_{C \in \colP_{>1}}C\), for all \(c \in C \in \colP_{>1}\), exists \(r \in R \in \rowP_{>1}\) and \(C \in \colP_{>1}\) such that \(f^r(C) = c\).
  Then let \(\tilde{x}_C \coloneqq \sum_{c \in C}A_{r,c}x_c\). Since if \(f^{r}(C)= f^{r'}(C')\) implies that \(C=C'\), \(x\) is well defined.
  Lastly for all \(R \in \rowP\) we have:
  \[\tilde{A}_R\tilde{x} = \sum_{r \in R} \left( \sum_{C \in \colP_{=1}}\tilde{\rho}_rA_{r,c}\tilde{x}_C + \sum_{C\in \supp(\tilde{A}_r)_{>1}} \tilde{x}_C \right) = \sum_{r \in R} \left( \sum_{C \in \colP_{=1}}\tilde{\rho}_rA_{r,c}x_C + \sum_{C\in \supp(\tilde{A}_r)_{>1}} \sum_{c \in C}A_{r,c}x_c \right) = \sum_{r \in R} \tilde{\rho_r} b_r = \tilde{b}_R 
  \]
  \qed
\end{proof}


\section{APPLICATION TO CAPACITY EXPANSION PROBLEM}
We now apply the results of the previous section to the Capacity Expansion Problem. 
\textcolor{violet}{
TODO:
\begin{itemize}
  \item What are the connected components of the hypergraph as defined in the previous sectors? each connected component looks like the hypergraph of the ED at a fixed timestep. Why can we not consider the edges corresponding to hydrogen storage? because however \(\rho\)s are chosen, they hold, so they don't force \(\rho\) to be equal over the nodes it connects.
  \item What does it mean? Given an aggregated problem, we are interested in which time intervals are problematic, since the ones which have well define \(\rho\) could be disgragated and obtain the same solution, we disgragate the ones in which the \(\rho\)s are far from being well defines, that is we have two constraints in the same connected components with really different \(\rho_r\).
  \item What is \(\rho_r\), since the aggregated variables are only second stage variables. Let's consider \(\rho_r\) with \(r \in R\), and let \(t_r\) and \(n \in \cN\) be respectively the time step and the node corresponding to the constraint \(r\).Let the net energy production at time \(t\) in \(n\): that is demand in \(n\) minus any renewable power produced in \(n\). Then \(\rho_r\) corresponds to fraction between the net energy production at time \(t\) and the net energy production during the interval \(T\) with \(t \in T\).
  \item How to disaggregate: Thus we calculate \(\rho_(n,t)\) for all nodes in the network and al timestep, and disagregate thos with highest variance for fixed \(t\). (since, fixed t the should all be equal for the solution be feasible for the problem obtained by disagregating the time interval T). \\
  \item How much to disaggregate: One could either subdivide each time interval into finer time intervals, or to the single timesteps. For the former, one could keep the intervals in which the variance of \(\rho_r\) is small, together, and divide in single timesteps the rest.
  \item Initial aggregation: to calculate \(\rho_r\) we need to have solved already an aggregated problem, so it's not too insightful. But we can start by grouping together intervals by putting "peaks" on the extremes, that is peak of demand and production, and then subdividing equally the so obtained intervals.
  \item Write well how to calculate \(\rho_r\)
\end{itemize}
}
\section{COMPUTATIONAL RESULTS}
\subsection{SINGLE NODE NETWORK}
First, an electrical grid with a single node is considered (corresponding ideally to an area with uniform
weather conditions, highly connected at low cost). A first section will consider realistic parameter
combinations and describe the results given by the solver, conducting a parameter sensitivity analysis. A
second section will describe a validation function that checks the results of the capacity expansion
problem for feasibility on new scenarios. Concurrently, a cost function is designed to give more realistic
cost estimates compared to the optimal value given by the solver.
\subsection{MULTIPLE NODE NETWORK}
Results are computed for a multiple node network, with additional edge variables and parameters. When
considering a network with more than a single node, computational costs increase rapidly. Thus in the
first section, a small analysis is carried out to determine acceptable time steps on which time dependent
data can be aggregated (the gathered data is usually on hourly steps) while maintaining the quality of the
solution. Some examples are then considered, and the network dynamics that arise with the introduction
of edge variables are described. A mixed approach is then used to design a validation function that can
deal with the complexity arising from the introduction of the network structure in the model.
\section{CONCLUSIONS}

%\begin{acknowledgements}
%If you'd like to thank anyone, place your comments here
%and remove the percent signs.
%\end{acknowledgements}


% Authors must disclose all relationships or interests that 
% could have direct or potential influence or impart bias on 
% the work: 
%
% \section*{Conflict of interest}
%
% The authors declare that they have no conflict of interest.


% BibTeX users please use one of
%\bibliographystyle{spbasic}      % basic style, author-year citations
%\bibliographystyle{spmpsci}      % mathematics and physical sciences
%\bibliographystyle{spphys}       % APS-like style for physics
%\bibliography{}   % name your BibTeX data base

% Non-BibTeX users please use
\begin{thebibliography}{}
%
% and use \bibitem to create references. Consult the Instructions
% for authors for reference list style.
%
\bibitem{RefJ}
% Format for Journal Reference
Author, Article title, Journal, Volume, page numbers (year)
% Format for books
\bibitem{RefB}
Author, Book title, page numbers. Publisher, place (year)
% etc


\bibitem{European_H2_Market_landscape}
Author, European Hydrogen Market Landscape - November 2023 Report, page numbers. Publisher, place (year)

%@article{European_H2_Market_landscape,
%title = {European Hydrogen Market Landscape - November 2023 Report},
% journal = {European Journal of Operational Research},
% volume = {},
% number = {1},
% pages = {},
% year = {2023},
% doi = {},
% url = {https://observatory.clean-hydrogen.europa.eu/sites/default/files/2023-11/Report%2001%20-%20November%202023%20-%20The%20European%20hydrogen%20market%20landscape.pdf},
% author = {European Hydrogen Observatory},
% keywords = {},
% abstract = {}
% }

\bibitem{WindDataSet}
Author, Book Title, page numbers. Publisher, place (year)

% @article{WindDataSet,
% title = {Using bias-corrected reanalysis to simulate current and future wind power output},
% journal = {Energy},
% volume = {114},
% pages = {1224-1239},
% year = {2016},
% issn = {0360-5442},
% doi = {https://doi.org/10.1016/j.energy.2016.08.068},
% url = {https://www.sciencedirect.com/science/article/pii/S0360544216311811},
% author = {Iain Staffell and Stefan Pfenninger},
% keywords = {Wind power, Wind farm, Reanalysis, Capacity factor, Energy yield, Europe},
% abstract = {Reanalysis models are rapidly gaining popularity for simulating wind power output due to their convenience and global coverage. However, they should only be relied upon once thoroughly proven. This paper reports the first international validation of reanalysis for wind energy, testing NASA's MERRA and MERRA-2 in 23 European countries. Both reanalyses suffer significant spatial bias, overestimating wind output by 50% in northwest Europe and underestimating by 30% in the Mediterranean. We derive national correction factors, and show that after calibration national hourly output can be modelled with R2 above 0.95. Our underlying data are made freely available to aid future research. We then assess Europe's wind resources with twenty-year simulations of the current and potential future fleets. Europe's current average capacity factor is 24.2%, with countries ranging from 19.5% (Germany) to 32.4% (Britain). Capacity factors are rising due to improving technology and locations; for example, Britain's wind fleet is now 23% more productive than in 2005. Based on the current planning pipeline, we estimate Europe's average capacity factor could increase by nearly a third to 31.3%. Countries with large stakes in the North Sea will see significant gains, with Britain's average capacity factor rising to 39.4% and Germany's to 29.1%.}
% }


\bibitem{PVDataSet}
Author, Book Title, page numbers. Publisher, place (year)
% @article{PVDataSet,
% title = {Long-term patterns of European PV output using 30 years of validated hourly reanalysis and satellite data},
% journal = {Energy},
% volume = {114},
% pages = {1251-1265},
% year = {2016},
% issn = {0360-5442},
% doi = {https://doi.org/10.1016/j.energy.2016.08.060},
% url = {https://www.sciencedirect.com/science/article/pii/S0360544216311744},
% author = {Stefan Pfenninger and Iain Staffell},
% keywords = {Solar energy, Meteorological reanalysis, Satellite irradiance estimation, Renewables, Grid integration of renewables},
% abstract = {Solar PV is rapidly growing globally, creating difficult questions around how to efficiently integrate it into national electricity grids. Its time-varying power output is difficult to model credibly because it depends on complex and variable weather systems, leading to difficulty in understanding its potential and limitations. We demonstrate how the MERRA and MERRA-2 global meteorological reanalyses as well as the Meteosat-based CM-SAF SARAH satellite dataset can be used to produce hourly PV simulations across Europe. To validate these simulations, we gather metered time series from more than 1000 PV systems as well as national aggregate output reported by transmission network operators. We find slightly better accuracy from satellite data, but greater stability from reanalysis data. We correct for systematic bias by matching our simulations to the mean bias in modeling individual sites, then examine the long-term patterns, variability and correlation with power demand across Europe, using thirty years of simulated outputs. The results quantify how the increasing deployment of PV substantially changes net power demand and affects system adequacy and ramping requirements, with heterogeneous impacts across different European countries. The simulation code and the hourly simulations for all European countries are available freely via an interactive web platform, www.renewables.ninja.}
% }


\bibitem{Dunkelflaut}
Author, Book Title, page numbers. Publisher, place (year)
% @Article{Dunkelflaut,
% AUTHOR = {Li, Bowen and Basu, Sukanta and Watson, Simon J. and Russchenberg, Herman W. J.},
% TITLE = {A Brief Climatology of Dunkelflaute Events over and Surrounding the North and Baltic Sea Areas},
% JOURNAL = {Energies},
% VOLUME = {14},
% YEAR = {2021},
% NUMBER = {20},
% ARTICLE-NUMBER = {6508},
% URL = {https://www.mdpi.com/1996-1073/14/20/6508},
% ISSN = {1996-1073},
% DOI = {10.3390/en14206508}
% }



\bibitem{betaPV}
Author, Book Title, page numbers. Publisher, place (year)
% @article{betaPV,
% title = {Prediction interval of wind power using parameter optimized Beta distribution based LSTM model},
% journal = {Applied Soft Computing},
% volume = {82},
% pages = {105550},
% year = {2019},
% issn = {1568-4946},
% doi = {https://doi.org/10.1016/j.asoc.2019.105550},
% url = {https://www.sciencedirect.com/science/article/pii/S1568494619303308},
% author = {Xiaohui Yuan and Chen Chen and Min Jiang and Yanbin Yuan},
% keywords = {Wind power, Prediction interval, Long short-term memory neural network, Beta distribution, Particle swarm optimization},
% abstract = {Prediction interval of wind power (PIWP) is crucial to assessing the economic and safe operation of the wind turbine and providing support for analysis of the stability of power systems. The hybrid model (Beta-PSO-LSTM) of long short-term memory (LSTM) neural network and Beta distribution function based particle swarm optimization (PSO) is put forward for prediction interval of wind power. In order to enhance the performance of the Beta-PSO-LSTM for PIWP in training process, wind power series are divided into different power intervals, and then the Beta-PSO-LSTM is used to estimate each power interval of the original wind power series. Furthermore, based on the analysis of the interval forecasting error information in wind power training data set, Beta distribution model is proposed to get better PIWP, and PSO is used to optimize the parameters of the model. Finally, the proposed Beta-PSO-LSTM model is compared with the Beta distribution optimized by PSO based the BP neural network (Beta-PSO-BP), the normal distribution based LSTM neural network (Norm-LSTM), Beta distribution based LSTM neural network (Beta-LSTM), and Beta distribution optimized by iterative method based LSTM neural network (Beta-IM-LSTM) for PIWP. The simulation results show that the PIWP obtained by the Beta-PSO-LSTM model has higher reliability and narrower interval bandwidth, which can provide decision support for the safe and stable operation of power systems.}
% }


\bibitem{GaussCopula}
Author, Book Title, page numbers. Publisher, place (year)
% @ARTICLE{GaussCoupula,
%   author={Papaefthymiou, George and Kurowicka, Dorota},
%   journal={IEEE Transactions on Power Systems}, 
%   title={Using Copulas for Modeling Stochastic Dependence in Power System Uncertainty Analysis}, 
%   year={2009},
%   volume={24},
%   number={1},
%   pages={40-49},
%   keywords={Power system modeling;Stochastic systems;Power system analysis computing;Uncertainty;Random variables;Power system planning;Stochastic processes;Power generation;Context modeling;Aggregates;Copula;correlation;Monte Carlo simulation;stochastic dependence;stochastic generation;uncertainty analysis;wind power},
%   doi={10.1109/TPWRS.2008.2004728}}


\bibitem{weibullwind}
Author, Book Title, page numbers. Publisher, place (year)
% @article{weibullwind,
% title = {Evaluation of wind power production prospective and Weibull parameter estimation methods for Babaurband, Sindh Pakistan},
% journal = {Energy Conversion and Management},
% volume = {78},
% pages = {956-967},
% year = {2014},
% issn = {0196-8904},
% doi = {https://doi.org/10.1016/j.enconman.2013.06.062},
% url = {https://www.sciencedirect.com/science/article/pii/S019689041300589X},
% author = {Shahnawaz Farhan Khahro and Kavita Tabbassum and Amir Mahmood Soomro and Lei Dong and Xiaozhong Liao},
% keywords = {Wind energy, Power density function, Weibull distribution, Frequency distribution, Wind rose},
% abstract = {Pakistan is currently experiencing an acute shortage of energy and urgently needs new sources of affordable energy that could alleviate the misery of the energy starved masses. At present the government is increasing not only the conventional energy sources like hydel and thermal but also focusing on the immense potential of renewable energy sources like; solar, wind, biogas, waste-to-energy etc. The recent economic crisis worldwide, global warming and climate change have also emphasized the need for utilizing economic feasible energy sources having lowest carbon emissions. Wind energy, with its sustainability and low environmental impact, is highly prominent. The aim of this paper is to explore the wind power production prospective of one of the sites in south region of Pakistan. It is worth mentioning here that this type of detailed analysis is hardly done for any location in Pakistan. Wind power densities and frequency distributions of wind speed at four different altitudes along with estimated wind power expected to be generated through commercial wind turbines is calculated. Analysis and comparison of 5 numerical methods is presented in this paper to determine the Weibull scale and shape parameters for the available wind data. The yearly mean wind speed of the considered site is 6.712m/s and has power density of 310W/m2 at 80m height with high power density during April to August (highest in May with wind speed 9.595m/s and power density 732W/m2). Economic evaluation, to exemplify feasibility of installing wind turbines, is also done. The estimated cost of per kWh of electricity from wind is calculated as 0.0263US$/kWh. Thus the candidate site is recommended for some small stand-alone systems as well as for wind farm.}
% }


\bibitem{future_climate}
Author, Book Title, page numbers. Publisher, place (year)
% @article{future_climate,
%     author = {Bett, P. E., Thornton, H. E., and Clark, R. T.},
%     title = {European wind variability over 140 yr},
%     journal = {Adv. Sci. Res., 10, 51–58},
%     year = {2013}
% }




\end{thebibliography}

\end{document}
% end of file template.tex

